{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\ttext = file.read()\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# load English data\n",
    "filename_eng = 'europarl-v7.nl-en.en'\n",
    "eng_data = load_doc(filename_eng)\n",
    "\n",
    "# load Dutch data\n",
    "filename_nl = 'europarl-v7.nl-en.nl'\n",
    "nl_data = load_doc(filename_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and loading of data using:\n",
    "https://machinelearningmastery.com/prepare-french-english-dataset-machine-translation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    "\treturn doc.strip().split('\\n')\n",
    "\n",
    "# clean a list of lines\n",
    "def clean_lines(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor line in lines:\n",
    "\t\t# normalize unicode characters\n",
    "\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "\t\tline = line.decode('UTF-8')\n",
    "\t\t# tokenize on white space\n",
    "\t\tline = line.split()\n",
    "\t\t# convert to lower case\n",
    "\t\tline = [word.lower() for word in line]\n",
    "\t\t# remove punctuation from each token\n",
    "\t\tline = [word.translate(table) for word in line]\n",
    "\t\t# remove non-printable chars form each token\n",
    "\t\tline = [re_print.sub('', w) for w in line]\n",
    "\t\t# remove tokens with numbers in them\n",
    "\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t# store as string\n",
    "\t\tcleaned.append(' '.join(line))\n",
    "\treturn cleaned\n",
    "\n",
    "\n",
    "# transform data into sentences and clean them\n",
    "sentences_eng = to_sentences(eng_data)\n",
    "sentences_eng = clean_lines(sentences_eng)\n",
    "\n",
    "\n",
    "# transform data into sentences and clean them\n",
    "sentences_nl = to_sentences(nl_data)\n",
    "sentences_nl = clean_lines(sentences_nl)\n",
    "\n",
    "\n",
    "paired_sent = []\n",
    "for eng_line, nl_line in zip(sentences_eng, sentences_nl):\n",
    "\tpaired_sent.append([eng_line, nl_line])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: cleaned_pairs.txt\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def save_clean_pairs(paired_sent, filename):\n",
    "\twith open(filename, 'wb') as f:\n",
    "\t\tpickle.dump(paired_sent, f)\n",
    "\tprint('Saved: %s' % filename)\n",
    "\n",
    "save_clean_pairs(paired_sent, \"cleaned_pairs.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
