{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kdnuggets.com/2019/11/create-vocabulary-nlp-tasks-python.html?__cf_chl_tk=LPyQpuVXIlt8Tfy._P5aqelhRrIBj14.w1y7j3sgD0c-1710433843-0.0.1.1-1685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index itself in the dictionary is the thing that is embedded.\n",
    "The word is the key and the index is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\ttext = file.read()\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# load English data\n",
    "clean_eng = load_doc('cleaned_eng.txt')\n",
    "\n",
    "# load Dutch data\n",
    "clean_nl = load_doc('cleaned_nl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "word2count = {}\n",
    "index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "num_words = 3\n",
    "num_sentences = 0\n",
    "longest_sentence = 0\n",
    "\n",
    "def add_word(word):\n",
    "        if word not in word2index:\n",
    "            # First entry of word into vocabulary\n",
    "            global num_words\n",
    "            word2index[word] = num_words\n",
    "            word2count[word] = 1\n",
    "            index2word[num_words] = word\n",
    "            num_words += 1\n",
    "        else:\n",
    "            # Word exists; increase word count\n",
    "            word2count[word] += 1\n",
    "\n",
    "def add_sentence(sentence):\n",
    "        global num_sentences\n",
    "        global longest_sentence\n",
    "        sentence_len = 0\n",
    "        for word in sentence.split(' '):\n",
    "            sentence_len += 1\n",
    "            add_word(word)\n",
    "        if sentence_len > longest_sentence:\n",
    "            # This is the longest sentence\n",
    "            longest_sentence = sentence_len\n",
    "        # Count the number of sentences\n",
    "        num_sentences += 1\n",
    "\n",
    "def to_word(index):\n",
    "        return index2word[index]\n",
    "\n",
    "def to_index(word):\n",
    "    return word2index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('cleaned_eng.txt')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    add_sentence(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumption\n"
     ]
    }
   ],
   "source": [
    "word = to_word(3)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "\n",
    "https://www.kdnuggets.com/2019/11/create-vocabulary-nlp-tasks-python.html?__cf_chl_tk=LPyQpuVXIlt8Tfy._P5aqelhRrIBj14.w1y7j3sgD0c-1710433843-0.0.1.1-1685\n",
    "\n",
    "https://blog.paperspace.com/seq2seq-translator-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "embeddings = nn.Embedding(num_words, 10)\n",
    "lookup_tensor = torch.tensor([word2index[\"zitting\"]])\n",
    "zitting_embed = embeddings(lookup_tensor)\n",
    "print(zitting_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, pipeline\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
